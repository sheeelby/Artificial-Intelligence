# Практическая № 2 (18 вариант) Лыков Даниил

library("lmtest")
library("GGally")
library("car")

data = na.omit(swiss)

data
summary(data)
ggpairs(data)

#----------------------------------------Корректировка исходной зависимости----------------------------------------------

# Исходная зависимость

model_main = lm(Infant.Mortality~Education+Agriculture+Catholic, data)
summary(model_main)

# Мы видим, что в исходной модели очень низкий коэффициент детерминации(R^2), а также нет зависимости
# между регрессорами и объясняемой переменной, поэтому дальнейшие улучшения модели не приведут к желаемому результату.
# Чтобы улучшить модель введем новый регрессор Fertility.

model_corrected = lm(Infant.Mortality~Education+Agriculture+Catholic+Fertility, data)
summary(model_corrected)

# Наша модель стала намного лучше. Это заметно, ведь коэффициент детерминации(R^2) вырос в несколько раз, став около 17%, 
# а также появились звездочки, что свидетельствует о зависимости между объясняемой и объясняющими переменными.

#---------------------------------------Проверка регрессоров на линейную зависимость-------------------------------------

# Проверим, нет ли в наборе данных линейной зависимости.
# Для этого построим зависимости между регрессорами и увидим,
# есть ли между ними зависимость с помощью коэффициента детерминации(R^2).

model01 = lm(Agriculture~Catholic+Fertility+Education, data)
model02 = lm(Catholic~Agriculture+Fertility+Education, data)
model03 = lm(Fertility~Agriculture+Catholic+Education, data)
model04 = lm(Education~Agriculture+Catholic+Fertility, data)

summary(model01)
# Коэффициент детерминации (R^2) около 55 %.
summary(model02)
# R^2 около 42 %.
summary(model03)
# R^2 около 62 %.
summary(model04)
# R^2 около 70 %.

# Мы видим, что R^2 у всех регрессоров огромен. Однако, больше всего он наблюдается у регрессора Education.
# Его R^2 = 70%, а кол-во звездочек у каждого регрессора большое,
# а значит он линейно зависим от остальных регрессоров.
# Исключим его из откорректированной модели и посмотрим на R^2.

model_working = lm(Infant.Mortality~Agriculture+Catholic+Fertility, data)
summary(model_working)

# Видим, что R^2 у наше модели стал даже лучше без регрессора Education, поэтому будем работать с этой моделью.

# Проверим, нет ли в наборе данных линейной зависимости уже без регрессора Education.
# Для этого построим зависимости между регрессорами и увидим,
# есть ли между ними зависимость с помощью коэффициента детерминации(R^2).
# Также проверим это с помощью VIF.

model1 = lm(Agriculture~Catholic+Fertility, data)
model2 = lm(Catholic~Agriculture+Fertility, data)
model3 = lm(Fertility~Agriculture+Catholic, data)

summary(model1)
# Коэффициент детерминации (R^2) около 16 %, что свидетельствует о линейной независимости регрессора
# Agriculture от других регрессоров.
summary(model2)
# R^2 около 24 %, что свидетельствует о линейной независимости регрессора
# Catholic от других регрессоров.
summary(model3)
# R^2 около 21 %, что свидетельствует о линейной независимости регрессора
# Fertility от других регрессоров.

# Теперь с помощью VIF удостоверимся в верности наших рассуждений.
vif(model_working)

# Видим, что наши регрессоры действительно линейно независимы друг от друга, так как значения из команды VIF
# у всех регрессоров меньше 1,4.

#----------------------------------------Проверка модели по методу наименьших квадратов-------------------------------------

# В корректировке модели мы уже проводили некоторые оценки исходной модели, поэтому оценим откорректированную
# рабочую модель.

# Посмотрим, как будет меняться R^2 при добавлении регрессоров в модель.

model_working1 = lm(Infant.Mortality~Fertility, data)
summary(model_working1)

# Видим, что R^2 у модели будет около 15 %, а кол-во звезд у регрессора будет немалое.

model_working2 = lm(Infant.Mortality~Fertility+Agriculture, data)
summary(model_working2)

# Видим, что R^2 у модели увеличился и стал почти 19 %, однако звезд у добавляемого регрессора вообще нет.

model_working3 = lm(Infant.Mortality~Fertility+Agriculture+Catholic, data)
summary(model_working3)

# Видим, что R^2 у модели при добавлении регрессора Catholic упал на 2 %, а значит стоит исключить его из нашей модели, 
# ведь объясняемая переменная никак не зависит от данного регрессора.

# Получаем хорошую модель

model_good = lm(Infant.Mortality~Fertility+Agriculture, data)

#---------------------------------------Ввод логарифмов от регрессоров в модель-------------------------------------------

# Для начала исследуем регрессоры на линейную зависимость от исходных.

model001 = lm(log(Fertility)~Fertility, data)
model002 = lm(log(Agriculture)~Agriculture, data)

summary(model001)
# Видим, что R^2 около 98%.
summary(model002)
# Видим, что R^2 около 76%.

# Делаем вывод, что исходные регрессоры необходимо заменить логарифмами, чтобы избежать линейной зависимости.
# Построим зависимости с логарифмами от регрессоров

model_log1 = lm(Infant.Mortality~I(log(Fertility))+Agriculture, data)
summary(model_log1)

# В данной модели незначительно уменьшился R^2, выросли стандартные ошибки.

model_log2 = lm(Infant.Mortality~Fertility+I(log(Agriculture)), data)
summary(model_log2)

# В данной модели уменьшился R^2 почти на 3 %.

model_log3 = lm(Infant.Mortality~I(log(Fertility))+I(log(Agriculture)), data)
summary(model_log3)

# В данной модели тоже уменьшился R^2 на 3 %, а к тому же выросли стандартные ошибки.

# Делаем вывод, что логарифмы от регрессоров не улучшают нашу модель, поэтому стоит вводить различные произведения
# регрессоров, чтобы добиться ее улучшения.

#-------------------------------------Ввод различных произведений пар регрессоров------------------------------------------

# Также, как и в случае с логарифмами исследуем квадраты регрессоров на линейную зависимость от исходных регрессоров.

model0001 = lm((Fertility)^2~Fertility, data)
model0002 = lm((Agriculture)^2~Agriculture, data)
model0003 = lm(Agriculture*Fertility~I(Agriculture*Fertility), data)

summary(model0001)
# Видим, что R^2 около 98%.
summary(model0002)
# Видим, что R^2 около 94%.
summary(model0003)
# Здесь, мы также видим, что подгонка слишком хорошая.

# Делаем вывод, что исходные регрессоры необходимо заменить квадратами или произведением, чтобы избежать линейной зависимости.
# Построим зависимости с всевозможными парами произведений регрессоров

model_a = lm(Infant.Mortality~I(Fertility^2)+Agriculture, data)
model_b = lm(Infant.Mortality~Fertility+I(Agriculture^2), data)
model_c = lm(Infant.Mortality~I(Fertility*Agriculture), data)

summary(model_a)
# Видим, что R^2 около 18%.
summary(model_b)
# Видим, что R^2 около 21%.
summary(model_c)
# Здесь, мы видим, что R^2 стал отрицательным, что свидетельствует о плохой зависимости.

# Вывод: Из всех моделей лучшая - model_b.
# Ее R^2 самый лучший из всех моделей, стандартные ошибки маленькие, есть звездочки у каждого регрессора.

model_best = lm(Infant.Mortality~Fertility+I(Agriculture^2), data)
summary(model_best)

#----------------------------Построение доверительных интервалов для всех коэффициентов в модели--------------------

# Для того, чтобы найти доверительные интервалы для коэффициентов в модели, необходимо найти значение t-критерия
# Стьюдента. Кол-во измерений в обучающей выборке 47, из них 3 коэффициента рассчитаны.
# Число степеней свободы в модели 47 - 3 = 44. Для p = 95% критерий Стьюдента будет:

t_critical = qt(0.975, df = 44)
t_critical

# Значение t-критерия Стьюдента приблизительно 2.015

# Доверительный интервал строится по формуле [Estimate - t * Std.Error; Estimate + t * Std.Error]

# Найдем доверительный интервал для коэффициента k1(коэффициента Fertility).
# Estimate(Fertility) = 0.12; Std.Error(Fertility) = 0.03;
# Доверительный интервал для k1:[0.12 - 2.015*0.03; 0.12 + 2.015*0.03], k1:[0.05955; 0.18045]
# В этот интервал не попадает 0, значит коэффициент точно не равен 0 на уровне значимости 5 %.

# Найдем доверительный интервал для коэффициента k1(коэффициента Agriculture^2).
# Estimate(Agriculture^2) = -0.0003; Std.Error(Agriculture^2) = 0.0001;
# Доверительный интервал для k1:[-0.0003 - 2.015*0.0001; -0.0003 + 2.015*0.0001], k1:[-0.0005015; -0.0000985]
# В этот интервал не попадает 0, значит коэффициент точно не равен 0 на уровне значимости 5 %.

# Найдем доверительный интервал для прогноза с регрессорами Fertility=25, I(Agriculture^2)=900, p=95%

new.data = data.frame(Fertility = 25, Agriculture = 30)
predict(model_best, new.data, interval = "confidence")

# Прогноз модели (для Fertility = 25, Agriculture = 30) оценивается как 15.47
# Доверительный интервал: [12.59; 18.35]
