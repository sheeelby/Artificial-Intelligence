{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNtLJlW4v5VF"
      },
      "source": [
        "## Классификация текстов\n",
        "\n",
        "В данном задании мы будем работать над задачей классификации последовательностей (текстов) с использованием различных методов векторизации слов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grIwIEWAv5VK"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from IPython import display\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from sklearn import naive_bayes\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "out_dict = dict()\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CijSj69Ov5VN"
      },
      "source": [
        "### Предобработка текста и токенизация\n",
        "\n",
        "Предобработка практически аналогична рассмотренной на предшествующем занятии. Библиотека `nltk` [link](https://www.nltk.org) широко используется при обработке текстов. По ссылке выше можно найти ее развернутое описание и документацию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiQRjnZ4OyL0"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "df = pd.read_csv(\n",
        "    \"https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv\",\n",
        "    delimiter=\"\\t\",\n",
        "    header=None,\n",
        ")\n",
        "texts_train = df[0].values[:5000]\n",
        "y_train = df[1].values[:5000]\n",
        "texts_test = df[0].values[5000:]\n",
        "y_test = df[1].values[5000:]\n",
        "\n",
        "\n",
        "tokenizer = WordPunctTokenizer()\n",
        "preprocess = lambda text: \" \".join(tokenizer.tokenize(text.lower()))\n",
        "\n",
        "text = 'How to be a grown-up at work: replace \"I don\\'t want to do that\" with \"Ok, great!\".'\n",
        "print(\n",
        "    \"before:\",\n",
        "    text,\n",
        ")\n",
        "print(\n",
        "    \"after:\",\n",
        "    preprocess(text),\n",
        ")\n",
        "\n",
        "texts_train = [preprocess(text) for text in texts_train]\n",
        "texts_test = [preprocess(text) for text in texts_test]\n",
        "\n",
        "# Small check that everything is done properly\n",
        "assert (\n",
        "    texts_train[5]\n",
        "    == \"campanella gets the tone just right funny in the middle of sad in the middle of hopeful\"\n",
        ")\n",
        "assert texts_test[74] == \"poetry in motion captured on film\"\n",
        "assert len(texts_test) == len(y_test)\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ElSQqMpOyL1"
      },
      "source": [
        "Следующие функции помогут вам с визуализацией процесса обучения сети."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dME0MB5EOyL1"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "\n",
        "def plot_train_process(\n",
        "    train_loss, val_loss, train_accuracy, val_accuracy, title_suffix=\"\"\n",
        "):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    axes[0].set_title(\" \".join([\"Loss\", title_suffix]))\n",
        "    axes[0].plot(train_loss, label=\"train\")\n",
        "    axes[0].plot(val_loss, label=\"validation\")\n",
        "    axes[0].legend()\n",
        "\n",
        "    axes[1].set_title(\" \".join([\"Validation accuracy\", title_suffix]))\n",
        "    axes[1].plot(train_accuracy, label=\"train\")\n",
        "    axes[1].plot(val_accuracy, label=\"validation\")\n",
        "    axes[1].legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualize_and_save_results(\n",
        "    model, model_name, X_train, X_test, y_train, y_test, out_dict\n",
        "):\n",
        "    for data_name, X, y, model in [\n",
        "        (\"train\", X_train, y_train, model),\n",
        "        (\"test\", X_test, y_test, model),\n",
        "    ]:\n",
        "        if isinstance(model, BaseEstimator):\n",
        "            proba = model.predict_proba(X)[:, 1]\n",
        "        elif isinstance(model, nn.Module):\n",
        "            proba = model(X).detach().cpu().numpy()[:, 1]\n",
        "        else:\n",
        "            raise ValueError(\"Unrecognized model type\")\n",
        "\n",
        "        auc = roc_auc_score(y, proba)\n",
        "\n",
        "        out_dict[f\"{model_name}_{data_name}\"] = auc\n",
        "        plt.plot(*roc_curve(y, proba)[:2], label=\"{} AUC={:.4f}\".format(data_name, auc))\n",
        "\n",
        "    plt.plot(\n",
        "        [0, 1],\n",
        "        [0, 1],\n",
        "        \"--\",\n",
        "        color=\"black\",\n",
        "    )\n",
        "    plt.legend(fontsize=\"large\")\n",
        "    plt.title(model_name)\n",
        "    plt.grid()\n",
        "    return out_dict\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvBUkzCTOyL1"
      },
      "source": [
        "## Повторение: основные понятия в глубоком обучении\n",
        "\n",
        "__Слой (layer)__ – некоторое преобразование над исходными данными. Простейший пример: линейный слой, являющийся линейным преобразованием над входящими данными (т.е. просто преобразование $WX +b$, как и в линейной регрессии).\n",
        "\n",
        "__Функция активации (activation function)__ – нелинейное преобразование, применяется ко всем данным пришедшим на вход поэлементно. Благодаря функциям активации нейронные сети делают *нелинейные преобразования* над исходными признаками, тем самым порождая более информативное признаковое описание.\n",
        "\n",
        "__Нейронная сеть (neural network)__ – композиция линейных и нелинейных преобразований (как правило, представимая в виде последовательности слоев и функций активации). Изучением нейронных сетей и их применимости в различных задачах занимается глубокое обучение (Deep Learning). В большинстве случаев вся нейронная сеть является одной сложной *дифференцируемой* функцией, что накладывает ограничения на возможность использование тех или иных преобразований.\n",
        "\n",
        "__Регуляризация (regularization)__ – механизм наложения ограничений на решение в зависимости от экспертных знаний и/или априорных предположений о решаемой задаче. Может быть представлена в форме дополнительного члена в функции потерь (например, $L1$ или $L2$ регуляризация), в форме ограничений на структуру модели (`Dropout`, `Batch Normalization`) и в других формах.\n",
        "\n",
        "__Функция потерь (loss function)__ – функция потерь, оценивающая качество полученного предсказания. Как правило, от функции потерь требуется свойство дифференцируемости (т.к. настройка параметров сети происходит методом *обратного распространения ошибки*). В некоторых случаях (например, в обучении с подкреплением) используются и недифференцируемые функции потерь/награды. Их использование требует доработки механизма обучения нейронных сетей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWjM_88WOyL2"
      },
      "source": [
        "## Работа с текстами и последовательностями\n",
        "\n",
        "* __Последовательности__. Данные – наборы значений, на которых задано отношение порядка. Значения могут быть дискретными (например, ДНК), или же могут принимать значения из непрерывного интервала (временной ряд энергопотребления дата центра). Перестановка значений приводит к потере информации. Нельзя нарушать отношение порядка (тестирование на прошлом, обучение на будущем).\n",
        "\n",
        "* __Тексты__. Данные – наборы слов/символов. По факту являются последовательностями значений из конечного алфавита, но обладают достаточно строгой внутренней структурой ввиду существования грамматики.\n",
        "\n",
        "В работе с естественным языком (в виде текста в первую очередь), а также в работе с последовательностями себя отлично зарекомендовали рекуррентные сети и сети, основанные на механизме внимания (attention mechanism), подобные модели Transformer, предложенной в 2017 году в работе Attention is all you need. Как рекуррентные, так и transformer-like модели учитывают зависимость элементов последовательности друг от друга (и в целом наличие порядка), что позволяет им порождать информативные признаковые представления автоматически (подобно сверточным сетям при работе с изображениями)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgd0Mlzsv5VO"
      },
      "source": [
        "### Задача №1. Мешок слов.\n",
        "\n",
        "Воспользуйтесь классическим подходом к векторизации текстов: мешком слов. Для этого вы можете как воспользоваться `CountVectorizer` из `sklearn`, так и самостоятельно реализованный вариант.\n",
        "\n",
        "Мешок слов сопоставляет каждому слову из словаря уникальный индекс (номер слова в словаре) и строит итоговый вектор для текста как набор счетчиков каждого слова из словаря. Этот подход эквивалентен построению суммы `one-hot` векторов для каждого из слов в тексте.\n",
        "\n",
        "#### __One-hot кодирование__.\n",
        "Каждому слову в языке можно сопоставить уникальный индекс и поставить слову в соответствие вектор, где нули стоят на всех местах, кроме заданного индекса. Такой подход называется one-hot кодированием. Пример такого кодирования можно увидеть ниже.\n",
        "\n",
        "*Пример: слово \"собака\" находится на третьем месте в словаре из 5 слов. Тогда ему будет соответствовать вектор `[0, 0, 1, 0, 0]`. Слово \"кошка\" стоит на втором месте, ему соответствует вектор `[0, 1, 0, 0, 0]`. Слово \"кот\" – на четвёртом, ему соответствует вектор `[0, 0, 0, 1, 0]`.*\n",
        "\n",
        "\n",
        "\n",
        "Обращаем ваше внимание, в части 1 используется лишь `k` наиболее часто встречаемых слов из обучающей части выборки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNHFsVuPv5VP"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "k = min(10000, len(set(\" \".join(texts_train).split())))\n",
        "\n",
        "counts = Counter(\" \".join(texts_train).split())\n",
        "\n",
        "bow_vocabulary = [key for key, val in counts.most_common(k)]\n",
        "\n",
        "\n",
        "def text_to_bow(text):\n",
        "    \"\"\"convert text string to an array of token counts. Use bow_vocabulary.\"\"\"\n",
        "    sent_vec = np.zeros(len(bow_vocabulary))\n",
        "    counts = Counter(text.split())\n",
        "    for i, token in enumerate(bow_vocabulary):\n",
        "        if token in counts:\n",
        "            sent_vec[i] = counts[token]\n",
        "    return np.array(sent_vec, \"float32\")\n",
        "\n",
        "\n",
        "X_train_bow = np.stack(list(map(text_to_bow, texts_train)))\n",
        "X_test_bow = np.stack(list(map(text_to_bow, texts_test)))\n",
        "\n",
        "# Small check that everything is done properly if you are using local bow implementation\n",
        "k_max = len(set(\" \".join(texts_train).split()))\n",
        "assert X_train_bow.shape == (len(texts_train), min(k, k_max))\n",
        "assert X_test_bow.shape == (len(texts_test), min(k, k_max))\n",
        "assert np.all(\n",
        "    X_train_bow[5:10].sum(-1) == np.array([len(s.split()) for s in texts_train[5:10]])\n",
        ")\n",
        "assert len(bow_vocabulary) <= min(k, k_max)\n",
        "assert X_train_bow[65, bow_vocabulary.index(\"!\")] == texts_train[65].split().count(\"!\")\n",
        "\n",
        "\n",
        "bow_model = LogisticRegression(max_iter=1500).fit(X_train_bow, y_train)\n",
        "\n",
        "out_dict = visualize_and_save_results(\n",
        "    bow_model, \"bow_log_reg_sklearn\", X_train_bow, X_test_bow, y_train, y_test, out_dict\n",
        ")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSg1inPqv5VR"
      },
      "source": [
        "Результаты неплохие, но явно видно переобучение. Этот вывод можно сделать судя по значительному превосходству качества (AUC ROC) на train выборке относительно test. Более того, на обучающей выборке качество стремится к единице, в то время как на отложенной – значительно ниже, т.е. модель уловила множество зависимостей, свойственных лишь обучающей выборке. Базово проблема переобучения рассматривалась в предыдущих занятиях и еще не раз встретится на курсе в дальнейшем.\n",
        "\n",
        "В данной задаче с переобучением мы разберемся в дальнейшем. Сейчас же реализуйте решение на основе логистической регрессии, но уже используя PyTorch. В результате вам должна быть доступна обученная модель, предсказывающая вероятности для двух классов. Качество на тестовой выборке должно не уступать логистической регрессии."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRN4ofOgv5VR"
      },
      "outputs": [],
      "source": [
        "model = # your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLx_3tOCv5VR"
      },
      "source": [
        "Не забывайте о функциях потерь: `nn.CrossEntropyLoss` объединяет в себе `LogSoftMax` и `NLLLoss`. Также не забывайте о необходимости перенести тензоры на используемый `device`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7dcCGLsv5VS"
      },
      "outputs": [],
      "source": [
        "loss_function = # your code here\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CK7iew17v5VS"
      },
      "outputs": [],
      "source": [
        "X_train_bow_torch = # your code here\n",
        "X_test_bow_torch = # your code here\n",
        "\n",
        "y_train_torch = # your code here\n",
        "y_test_torch = # your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O6nRBJ4OyL3"
      },
      "source": [
        "Функция ниже поможет с обучением модели. Часть кода необходимо реализовать самостоятельно."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4GGcyXYv5VT"
      },
      "outputs": [],
      "source": [
        "def train_model(\n",
        "    model,\n",
        "    opt,\n",
        "    X_train_torch,\n",
        "    y_train_torch,\n",
        "    X_val_torch,\n",
        "    y_val_torch,\n",
        "    n_iterations=500,\n",
        "    batch_size=32,\n",
        "    show_plots=True,\n",
        "    eval_every=50\n",
        "):\n",
        "    train_loss_history = []\n",
        "    train_acc_history = []\n",
        "    val_loss_history = []\n",
        "    val_acc_history = []\n",
        "\n",
        "    local_train_loss_history = []\n",
        "    local_train_acc_history = []\n",
        "    for i in range(n_iterations):\n",
        "\n",
        "        # sample batch_size random observations\n",
        "        ix = np.random.randint(0, len(X_train_torch), batch_size)\n",
        "        x_batch = X_train_torch[ix]\n",
        "        y_batch = y_train_torch[ix]\n",
        "\n",
        "        # predict log-probabilities or logits\n",
        "        y_predicted = # your code here\n",
        "\n",
        "        # compute loss, just like before\n",
        "        loss = # your code here\n",
        "\n",
        "        # compute gradients\n",
        "        # your code here\n",
        "\n",
        "        # Adam step\n",
        "        # your code here\n",
        "\n",
        "        # clear gradients\n",
        "        # your code here\n",
        "\n",
        "        local_train_loss_history.append(loss.item())\n",
        "        local_train_acc_history.append(\n",
        "            accuracy_score(\n",
        "                y_batch.to('cpu').detach().numpy(),\n",
        "                y_predicted.to('cpu').detach().numpy().argmax(axis=1)\n",
        "            )\n",
        "        )\n",
        "\n",
        "        if i % eval_every == 0:\n",
        "            train_loss_history.append(np.mean(local_train_loss_history))\n",
        "            train_acc_history.append(np.mean(local_train_acc_history))\n",
        "            local_train_loss_history, local_train_acc_history = [], []\n",
        "\n",
        "            predictions_val = model(X_val_torch)\n",
        "            val_loss_history.append(loss_function(predictions_val, y_val_torch).to('cpu').detach().item())\n",
        "\n",
        "            acc_score_val = accuracy_score(y_val_torch.cpu().numpy(), predictions_val.to('cpu').detach().numpy().argmax(axis=1))\n",
        "            val_acc_history.append(acc_score_val)\n",
        "\n",
        "            if show_plots:\n",
        "                display.clear_output(wait=True)\n",
        "                plot_train_process(train_loss_history, val_loss_history, train_acc_history, val_acc_history)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TILA0_Aiv5VU"
      },
      "outputs": [],
      "source": [
        "bow_nn_model = train_model(\n",
        "    model,\n",
        "    opt,\n",
        "    X_train_bow_torch,\n",
        "    y_train_torch,\n",
        "    X_test_bow_torch,\n",
        "    y_test_torch,\n",
        "    n_iterations=3000,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpeR3FUVOyL4"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "out_dict = visualize_and_save_results(\n",
        "    bow_nn_model,\n",
        "    \"bow_nn_torch\",\n",
        "    X_train_bow_torch,\n",
        "    X_test_bow_torch,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    out_dict,\n",
        ")\n",
        "\n",
        "assert (\n",
        "    out_dict[\"bow_log_reg_sklearn_test\"] - out_dict[\"bow_nn_torch_test\"] < 0.01\n",
        "), \"AUC ROC on test data should be close to the sklearn implementation\"\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEt4byBxv5VU"
      },
      "source": [
        "А теперь повторите процедуру обучения выше, но для различных значений `k` – размера словаря. В список results сохраните `AUC ROC` на тестовой части выборки для модели, обученной со словарем размера `k`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jq9qxODpv5VU"
      },
      "outputs": [],
      "source": [
        "vocab_sizes_list = np.arange(100, 5800, 700)\n",
        "results = []\n",
        "\n",
        "for k in vocab_sizes_list:\n",
        "    # your code here\n",
        "    predicted_probas_on_test_for_k_sized_dict = None\n",
        "    assert predicted_probas_on_test_for_k_sized_dict is not None\n",
        "    auc = roc_auc_score(y_test, predicted_probas_on_test_for_k_sized_dict)\n",
        "    results.append(auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1PgmU_nOyL5"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert len(results) == len(vocab_sizes_list), \"Check the code above\"\n",
        "assert min(results) >= 0.65, \"Seems like the model is not trained well enough\"\n",
        "assert results[-1] > 0.84, \"Best AUC ROC should not be lower than 0.84\"\n",
        "\n",
        "plt.plot(vocab_sizes_list, results)\n",
        "plt.xlabel(\"num of tokens\")\n",
        "plt.ylabel(\"AUC\")\n",
        "plt.grid()\n",
        "\n",
        "out_dict[\"bow_k_vary\"] = results\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA_3nEyHv5VV"
      },
      "source": [
        "### Задача №2: Использование TF-iDF признаков.\n",
        "\n",
        "Для векторизации текстов также можно воспользоваться TF-iDF. Это позволяет исключить из рассмотрения многие слова, не оказывающие значимого влияния при оценке непохожести текстов.\n",
        "\n",
        "Подробнее про TF-iDF можно почитать, например, [здесь](https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089).\n",
        "Там же можно почитать о его самостоятельной реализации.\n",
        "\n",
        "Ваша задача: векторизовать тексты используя TF-iDF (или `TfidfVectorizer` из `sklearn`, или реализовав его самостоятельно) и построить классификатор с помощью PyTorch, аналогичный задаче №1.\n",
        "\n",
        "Затем также оцените качество классификации по AUC ROC для различных размеров словаря.\n",
        "\n",
        "Качество классификации должно быть не ниже 0.86 AUC ROC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9GMylcBOyL5"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THMktAtZNAqP"
      },
      "outputs": [],
      "source": [
        "X_train_tfidf = # your code here\n",
        "X_test_tfidf = # your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHbOlK1dyws8"
      },
      "outputs": [],
      "source": [
        "model = # your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fioSJacvjr2v"
      },
      "outputs": [],
      "source": [
        "loss_function = # your code here\n",
        "opt = # your code here\n",
        "\n",
        "model_tf_idf = train_model(model, opt, X_train_tfidf_torch, y_train_torch, X_test_tfidf_torch, y_test_torch, n_iterations=3000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbE9Ry1jOyL6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "out_dict = visualize_and_save_results(\n",
        "    model_tf_idf,\n",
        "    \"tf_idf_nn_torch\",\n",
        "    X_train_tfidf_torch,\n",
        "    X_test_tfidf_torch,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    out_dict,\n",
        ")\n",
        "\n",
        "assert (\n",
        "    out_dict[\"tf_idf_nn_torch_test\"] >= out_dict[\"bow_nn_torch_test\"]\n",
        "), \"AUC ROC on test data should be better or close to BoW for TF-iDF features\"\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9VCRvYGOyL6"
      },
      "source": [
        "Аналогично задаче №1 повторите процедуру обучения для различных значений `k` – размера словаря и сохраните `AUC ROC` на тестовой части выборки в список `results`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cy9zzoFvOyL6"
      },
      "outputs": [],
      "source": [
        "vocab_sizes_list = np.arange(100, 5800, 700)\n",
        "results = []\n",
        "\n",
        "for k in vocab_sizes_list:\n",
        "    # your code here\n",
        "    predicted_probas_on_test_for_k_sized_dict = None\n",
        "    assert predicted_probas_on_test_for_k_sized_dict is not None\n",
        "    auc = roc_auc_score(y_test, predicted_probas_on_test_for_k_sized_dict)\n",
        "    results.append(auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iu35SERsOyL6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert len(results) == len(vocab_sizes_list), \"Check the code above\"\n",
        "assert min(results) >= 0.65, \"Seems like the model is not trained well enough\"\n",
        "assert results[-1] > 0.85, \"Best AUC ROC for TF-iDF should not be lower than 0.84\"\n",
        "\n",
        "plt.plot(vocab_sizes_list, results)\n",
        "plt.xlabel(\"num of tokens\")\n",
        "plt.ylabel(\"AUC\")\n",
        "plt.grid()\n",
        "\n",
        "out_dict[\"tf_idf_k_vary\"] = results\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo-aLAItv5VW"
      },
      "source": [
        "### Задача №3: Сравнение с Наивным Байесовским классификатором.\n",
        "\n",
        "Классические модели все еще способны показать хороший результат во многих задачах. Обучите наивный байесовский классификатор на текстах, векторизованных с помощью BoW и TF-iDF и сравните результаты с моделями выше.\n",
        "\n",
        "*Комментарий: обращаем ваше внимание, необходимо выбрать подходящее к данной задаче априорное распределение для признаков, т.е. выбрать верную версию классификатора из `sklearn`: `GaussianNB`, `MultinomialNB`, `ComplementNB`, `BernoulliNB`, `CategoricalNB`*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPseLyhSOyL6"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import # your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5Hy-mJnW5Hc"
      },
      "outputs": [],
      "source": [
        "clf_nb_bow = # your code here\n",
        "\n",
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "out_dict = visualize_and_save_results(clf_nb_bow, 'bow_nb_sklearn', X_train_bow, X_test_bow, y_train, y_test, out_dict)\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-T5evicOyL7"
      },
      "outputs": [],
      "source": [
        "clf_nb_tfidf = # your code here\n",
        "\n",
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "out_dict = visualize_and_save_results(clf_nb_tfidf, 'tf_idf_nb_sklearn', X_train_tfidf, X_test_tfidf, y_train, y_test, out_dict)\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rp2j-gTJOyL7"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert (\n",
        "    out_dict[\"tf_idf_nb_sklearn_test\"] > out_dict[\"bow_nb_sklearn_test\"]\n",
        "), \" TF-iDF results should be better\"\n",
        "assert (\n",
        "    out_dict[\"tf_idf_nb_sklearn_test\"] > 0.86\n",
        "), \"TF-iDF Naive Bayes score should be above 0.86\"\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvqsaoedv5VW"
      },
      "source": [
        "### Задача №4: Использование предобученных эмбеддингов\n",
        "#### __Построение эмбеддингов с помощью word2vec__.\n",
        "Предложенные выше подходы обладают существенными недостатками: они не учитывает смысл слов при сопоставлении вектора каждому из них. Поэтому расстояние между one-hot векторами для слов \"кошка\" и \"собака\", для слов \"кошка\" и \"самолет\" или для слов \"кошка\" и \"кот\" будет одинаковой. Для владеющего языком человека разница между словами очевидна, как и то, что \"кошка\" и \"кот\" гораздо ближе друг к другу по смыслу, чем \"кошка\" и \"самолет\". При построении информативного векторного представления также хотелось бы установить смысловую близость слов.\n",
        "\n",
        "С этим может помочь простая мысль (озвученная в различных формах множество раз): __слово в значительной мере определяется контекстом, в котором оно встречается__. На основании чего можно сделать простой вывод: для некоторых слов более характерен один контекст, а для других – другой. Именно на этой идее и построен word2vec (как и многие другие эмбеддинги).\n",
        "\n",
        "По слову можно научиться предсказывать контекст, в котором оно встречается. Конечно, результат не будет идеально точным. Но если модель делает предсказания лучше, чем случайным образом, значит, она улавливает какую-то связь. И тогда внутреннее представление модели для каждого слова и может использоваться в качестве искомого векторного представления, причем и в других задачах.\n",
        "\n",
        "\n",
        "Формулировка гипотезы выше (слово значительно связано с контекстом) позволяет использовать в качестве обучающей выборки все множество текстов для выбранного языка. Собрание сочинений классиков, статьи в энциклопедии, новостные заметки – все это становится обучающей выборкой. И векторные представления, полученные на основе данных текстов позволяют улавливать связь между этими словами.\n",
        "![](https://ruder.io/content/images/size/w2000/2016/04/word_embeddings_colah.png)\n",
        "*Image source: https://ruder.io/word-embeddings-1/*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBIOiAA-OyL7"
      },
      "source": [
        "В данной части для получения предобученных векторных представлений  мы воспользуемся предобученными эмбеддингами из библиотеки `gensim`. В нем доступно несколько эмбеддингов, предобученных на различных корпусах текстов. Полный список можно найти [здесь](https://radimrehurek.com/gensim/models/word2vec.html#pretrained-models). Напоминаем, что лучше использовать те эмбеддинги, которые были обучены на текстах похожей структуры.\n",
        "\n",
        "Ваша задача: обучить модель (достаточно логистической регрессии или же двуслойной неронной сети), используя усредненный эмбеддинг для всех токенов в отзыве, добиться качества не хуже, чем с помощью BoW/TF-iDF и снизить степень переобучения (разницу между AUC ROC на обучающей и тестовой выборках)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DP5td5Ivv5VW"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "gensim_embedding_model = # your code here, e.g. api.load(...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sC8wyIqY6Ce9"
      },
      "outputs": [],
      "source": [
        "def text_to_average_embedding(text, gensim_embedding_model):\n",
        "    # your code here\n",
        "    return embedding_for_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZ8-03TIJNjz"
      },
      "outputs": [],
      "source": [
        "X_train_emb = [\n",
        "    text_to_average_embedding(text, gensim_embedding_model) for text in texts_train\n",
        "]\n",
        "X_test_emb = [\n",
        "    text_to_average_embedding(text, gensim_embedding_model) for text in texts_test\n",
        "]\n",
        "\n",
        "assert (\n",
        "    len(X_train_emb[0]) == gensim_embedding_model.vector_size\n",
        "), \"Seems like the embedding shape is wrong\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Gw5B5JJ7Z1y"
      },
      "outputs": [],
      "source": [
        "X_train_emb_torch = # your code here\n",
        "X_test_emb_torch = # your code here\n",
        "\n",
        "y_train_torch = # your code here\n",
        "y_test_torch = # your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yQ2zL0bjgcD"
      },
      "outputs": [],
      "source": [
        "model = # your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IP-Be_CRHI1f"
      },
      "outputs": [],
      "source": [
        "loss_function = # your code here\n",
        "opt = # your code here\n",
        "\n",
        "model = train_model(model, opt, X_train_emb_torch, y_train_torch, X_test_emb_torch, y_test_torch, n_iterations=3000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZVqwXCXOyMA"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "out_dict = visualize_and_save_results(\n",
        "    model,\n",
        "    \"emb_nn_torch\",\n",
        "    X_train_emb_torch,\n",
        "    X_test_emb_torch,\n",
        "    y_train,\n",
        "    y_test,\n",
        "    out_dict,\n",
        ")\n",
        "assert (\n",
        "    out_dict[\"emb_nn_torch_test\"] > 0.87\n",
        "), \"AUC ROC on test data should be better than 0.86\"\n",
        "assert (\n",
        "    out_dict[\"emb_nn_torch_train\"] - out_dict[\"emb_nn_torch_test\"] < 0.1\n",
        "), \"AUC ROC on test and train data should not be different more than by 0.1\"\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfnjfrLqOyMB"
      },
      "source": [
        "### Выводы:\n",
        "_Сформулируйте выводы о каждом из подходов к векторизации слов, а также о работоспособности моделей (Naive Bayes, Logistic Regression, etc.)_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hohtOwysavfv"
      },
      "source": [
        "### Сдача задания\n",
        "Запустите код ниже для генерации посылки и сдайте на проверку в контест файл `submission_dict_hw_text_classification.json`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-lidlX4a_mM"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "FILENAME = \"submission_dict_hw_text_classification.json\"\n",
        "with open(FILENAME, \"w\") as iofile:\n",
        "    json.dump(out_dict, iofile)\n",
        "print(f\"File saved to `{FILENAME}`\")\n",
        "# __________end of block__________"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "NLP_hw01_texts.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Py3 Research",
      "language": "python",
      "name": "py3_research_kernel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}